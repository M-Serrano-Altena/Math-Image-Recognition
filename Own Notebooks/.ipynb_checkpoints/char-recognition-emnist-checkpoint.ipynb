{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c32c73b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T12:25:25.786722Z",
     "iopub.status.busy": "2024-11-27T12:25:25.786324Z",
     "iopub.status.idle": "2024-11-27T12:25:25.792194Z",
     "shell.execute_reply": "2024-11-27T12:25:25.790853Z",
     "shell.execute_reply.started": "2024-11-27T12:25:25.786670Z"
    },
    "papermill": {
     "duration": 0.008001,
     "end_time": "2024-12-02T13:44:45.358023",
     "exception": false,
     "start_time": "2024-12-02T13:44:45.350022",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Character Recognition - EMNIST data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41afebdd",
   "metadata": {
    "papermill": {
     "duration": 0.006151,
     "end_time": "2024-12-02T13:44:45.370912",
     "exception": false,
     "start_time": "2024-12-02T13:44:45.364761",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fcf0f75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T13:44:45.386226Z",
     "iopub.status.busy": "2024-12-02T13:44:45.385229Z",
     "iopub.status.idle": "2024-12-02T13:45:11.171434Z",
     "shell.execute_reply": "2024-12-02T13:45:11.170137Z"
    },
    "papermill": {
     "duration": 25.79703,
     "end_time": "2024-12-02T13:45:11.174321",
     "exception": false,
     "start_time": "2024-12-02T13:44:45.377291",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting emnist\r\n",
      "  Downloading emnist-0.0-py3-none-any.whl.metadata (3.7 kB)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from emnist) (1.26.4)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from emnist) (2.32.3)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from emnist) (4.66.4)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->emnist) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->emnist) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->emnist) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->emnist) (2024.8.30)\r\n",
      "Downloading emnist-0.0-py3-none-any.whl (7.3 kB)\r\n",
      "Installing collected packages: emnist\r\n",
      "Successfully installed emnist-0.0\r\n",
      "Collecting idx2numpy\r\n",
      "  Downloading idx2numpy-1.2.3.tar.gz (6.8 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from idx2numpy) (1.26.4)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from idx2numpy) (1.16.0)\r\n",
      "Building wheels for collected packages: idx2numpy\r\n",
      "  Building wheel for idx2numpy (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for idx2numpy: filename=idx2numpy-1.2.3-py3-none-any.whl size=7904 sha256=6e60d03b87fa95d100e55d1d68aa1d27e197122d4ea594fae58e774660b6578c\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/e0/f4/e7/643fc5f932ec2ff92997f43f007660feb23f948aa8486f1107\r\n",
      "Successfully built idx2numpy\r\n",
      "Installing collected packages: idx2numpy\r\n",
      "Successfully installed idx2numpy-1.2.3\r\n"
     ]
    }
   ],
   "source": [
    "!pip install emnist\n",
    "!pip install idx2numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c775b7fb",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-02T13:45:11.191641Z",
     "iopub.status.busy": "2024-12-02T13:45:11.191170Z",
     "iopub.status.idle": "2024-12-02T13:45:31.676427Z",
     "shell.execute_reply": "2024-12-02T13:45:31.675379Z"
    },
    "papermill": {
     "duration": 20.497279,
     "end_time": "2024-12-02T13:45:31.679200",
     "exception": false,
     "start_time": "2024-12-02T13:45:11.181921",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b56d44d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T13:45:31.697708Z",
     "iopub.status.busy": "2024-12-02T13:45:31.697036Z",
     "iopub.status.idle": "2024-12-02T13:45:39.691649Z",
     "shell.execute_reply": "2024-12-02T13:45:39.690122Z"
    },
    "papermill": {
     "duration": 8.00616,
     "end_time": "2024-12-02T13:45:39.694337",
     "exception": false,
     "start_time": "2024-12-02T13:45:31.688177",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import idx2numpy\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = idx2numpy.convert_from_file('/kaggle/input/emnist/emnist_source_files/emnist-byclass-train-images-idx3-ubyte')\n",
    "X_test = idx2numpy.convert_from_file('/kaggle/input/emnist/emnist_source_files/emnist-byclass-test-images-idx3-ubyte')\n",
    "\n",
    "y = idx2numpy.convert_from_file('/kaggle/input/emnist/emnist_source_files/emnist-byclass-train-labels-idx1-ubyte')\n",
    "y_test = idx2numpy.convert_from_file('/kaggle/input/emnist/emnist_source_files/emnist-byclass-test-labels-idx1-ubyte')\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bea6702a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T13:45:39.713751Z",
     "iopub.status.busy": "2024-12-02T13:45:39.712260Z",
     "iopub.status.idle": "2024-12-02T13:45:41.974179Z",
     "shell.execute_reply": "2024-12-02T13:45:41.973087Z"
    },
    "papermill": {
     "duration": 2.273811,
     "end_time": "2024-12-02T13:45:41.976741",
     "exception": false,
     "start_time": "2024-12-02T13:45:39.702930",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rescale_data(arr):\n",
    "    # rescale range from [0, 255] to [0, 1]\n",
    "    return arr / 255\n",
    "\n",
    "X_train = rescale_data(X_train)\n",
    "X_val = rescale_data(X_val)\n",
    "X_test = rescale_data(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a3db00c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T13:45:41.996344Z",
     "iopub.status.busy": "2024-12-02T13:45:41.995953Z",
     "iopub.status.idle": "2024-12-02T13:45:42.009464Z",
     "shell.execute_reply": "2024-12-02T13:45:42.008103Z"
    },
    "papermill": {
     "duration": 0.025743,
     "end_time": "2024-12-02T13:45:42.012045",
     "exception": false,
     "start_time": "2024-12-02T13:45:41.986302",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "def convert_to_grayscale(array):\n",
    "    # shape (x, y, 3) --> (x, y)\n",
    "    return np.dot(array[...,:3], [0.2989, 0.5870, 0.1140])\n",
    "\n",
    "def apply_gaussian_filter(image):\n",
    "    return gaussian_filter(image, sigma=1)\n",
    "\n",
    "def crop_to_roi(image):\n",
    "    rows = np.any(image > 0, axis=1)\n",
    "    cols = np.any(image > 0, axis=0)\n",
    "    row_start, row_end = np.where(rows)[0][[0, -1]]\n",
    "    col_start, col_end = np.where(cols)[0][[0, -1]]\n",
    "    return image[row_start:row_end+1, col_start:col_end+1]\n",
    "\n",
    "def center_image(image, canvas_size=28, border=2):\n",
    "    h, w = image.shape[:2]\n",
    "    aspect_ratio = w / h\n",
    "\n",
    "    # Calculate the new dimensions\n",
    "    if aspect_ratio > 1:  # Wider than tall\n",
    "        new_w = canvas_size - 2 * border\n",
    "        new_h = int(new_w / aspect_ratio)\n",
    "    else:  # Taller than wide\n",
    "        new_h = canvas_size - 2 * border\n",
    "        new_w = int(new_h * aspect_ratio)\n",
    "\n",
    "    image = np.expand_dims(image, axis=-1)  # Add channel axis (shape -> (h, w, 1) )\n",
    "    \n",
    "    # Resize while preserving the aspect ratio\n",
    "    image_resized = tf.image.resize(image, (new_h, new_w)).numpy()\n",
    "\n",
    "    image_resized = np.squeeze(image_resized, axis=-1) # remove channel axis again\n",
    "    \n",
    "    # Create the centered canvas\n",
    "    canvas = np.zeros((canvas_size, canvas_size), dtype=image.dtype)\n",
    "    row_start = (canvas_size - new_h) // 2\n",
    "    col_start = (canvas_size - new_w) // 2\n",
    "    canvas[row_start:row_start+new_h, col_start:col_start+new_w] = image_resized\n",
    "\n",
    "    return canvas\n",
    "\n",
    "\n",
    "def normalize_image(image):\n",
    "    return (image / np.max(image))\n",
    "\n",
    "\n",
    "def preprocess_image(image):\n",
    "    if len(image.shape) == 3 and image.shape[2] >= 3:\n",
    "        image = convert_to_grayscale(image)\n",
    "    elif len(image.shape) == 3 and image.shape[2] == 1:\n",
    "        image = np.squeeze(image, axis=-1)\n",
    "        \n",
    "    image = apply_gaussian_filter(image)\n",
    "    image = crop_to_roi(image)\n",
    "    image = center_image(image)\n",
    "    image = normalize_image(image)\n",
    "    return image.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f1e1de7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T13:45:42.031379Z",
     "iopub.status.busy": "2024-12-02T13:45:42.030909Z",
     "iopub.status.idle": "2024-12-02T13:45:42.039037Z",
     "shell.execute_reply": "2024-12-02T13:45:42.037601Z"
    },
    "papermill": {
     "duration": 0.02138,
     "end_time": "2024-12-02T13:45:42.041449",
     "exception": false,
     "start_time": "2024-12-02T13:45:42.020069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def load_and_preprocess_image(img_path, target_size=(28, 28), inverse=False):\n",
    "    \"\"\"\n",
    "    Load an image and make it a numpy array.\n",
    "    \"\"\"\n",
    "    img = Image.open(img_path)\n",
    "    \n",
    "    # grayscale\n",
    "    img = img.convert(\"L\")\n",
    "    \n",
    "    # Resize to 28x28\n",
    "    img = img.resize((28, 28))\n",
    "    \n",
    "    # Convert to NumPy array\n",
    "    img_array = np.array(img)\n",
    "    \n",
    "    # Normalize to [0, 1] and invert if needed\n",
    "    img_array = img_array / 255.0\n",
    "    if inverse:\n",
    "        img_array = 1 - img_array\n",
    "\n",
    "    img_array = preprocess_image(img_array)\n",
    "    \n",
    "    # Add a batch dimension (because the model expects a batch of images)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e80091d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T13:45:42.060038Z",
     "iopub.status.busy": "2024-12-02T13:45:42.059612Z",
     "iopub.status.idle": "2024-12-02T13:45:42.067973Z",
     "shell.execute_reply": "2024-12-02T13:45:42.066434Z"
    },
    "papermill": {
     "duration": 0.021625,
     "end_time": "2024-12-02T13:45:42.071513",
     "exception": false,
     "start_time": "2024-12-02T13:45:42.049888",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_and_preprocess_images_from_dir(dir_path, target_size=(28, 28), inverse=False):\n",
    "    X = []\n",
    "    for img in sorted(os.listdir(dir_path)):\n",
    "        img_path = os.path.join(dir_path, img)\n",
    "        if not os.path.isfile(img_path):\n",
    "            continue\n",
    "            \n",
    "        img_array = load_and_preprocess_image(img_path, target_size=target_size, inverse=inverse)\n",
    "        img_array = np.squeeze(img_array, axis=0)\n",
    "        X.append(img_array)\n",
    "\n",
    "    X = np.array(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d73880b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T13:45:42.089214Z",
     "iopub.status.busy": "2024-12-02T13:45:42.088791Z",
     "iopub.status.idle": "2024-12-02T13:45:42.095511Z",
     "shell.execute_reply": "2024-12-02T13:45:42.094052Z"
    },
    "papermill": {
     "duration": 0.018475,
     "end_time": "2024-12-02T13:45:42.098035",
     "exception": false,
     "start_time": "2024-12-02T13:45:42.079560",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from string import ascii_lowercase, ascii_uppercase\n",
    "alphabet_plus = \"0123456789\" + ascii_uppercase + ascii_lowercase\n",
    "label_map = {i: alphabet_plus[i] for i in range(len(alphabet_plus))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cb56fd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T13:45:42.119159Z",
     "iopub.status.busy": "2024-12-02T13:45:42.118575Z",
     "iopub.status.idle": "2024-12-02T13:45:42.774124Z",
     "shell.execute_reply": "2024-12-02T13:45:42.772571Z"
    },
    "papermill": {
     "duration": 0.669747,
     "end_time": "2024-12-02T13:45:42.776046",
     "exception": true,
     "start_time": "2024-12-02T13:45:42.106299",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m     plt\u001b[38;5;241m.\u001b[39msubplots_adjust(hspace\u001b[38;5;241m=\u001b[39mrow_spacing)\n\u001b[1;32m     11\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m---> 13\u001b[0m \u001b[43mplot_n_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 4\u001b[0m, in \u001b[0;36mplot_n_images\u001b[0;34m(X, y, n, row_spacing)\u001b[0m\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Show the first n images if available, otherwise show all images\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mmin\u001b[39m(n, X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m)):  \n\u001b[1;32m      5\u001b[0m     plt\u001b[38;5;241m.\u001b[39msubplot(n \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m5\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m5\u001b[39m, i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      6\u001b[0m     plt\u001b[38;5;241m.\u001b[39mimshow(X[i], cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgray\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Assuming 28x28 images\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_n_images(X, y, n=10, row_spacing=0.5):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    # Show the first n images if available, otherwise show all images\n",
    "    for i in range(min(n, X.shape[0], y.shape[0])):  \n",
    "        plt.subplot(n // 5 + 1, 5, i+1)\n",
    "        plt.imshow(X[i], cmap='gray')  # Assuming 28x28 images\n",
    "        plt.title(label_map[y[i]])\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.subplots_adjust(hspace=row_spacing)\n",
    "    plt.show()\n",
    "\n",
    "plot_n_images(X_train[10:], y_train[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386352a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T10:18:28.160616Z",
     "iopub.status.busy": "2024-11-29T10:18:28.160264Z",
     "iopub.status.idle": "2024-11-29T10:18:28.165712Z",
     "shell.execute_reply": "2024-11-29T10:18:28.164395Z",
     "shell.execute_reply.started": "2024-11-29T10:18:28.160574Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def one_hot_encode(y):\n",
    "    return keras.utils.to_categorical(y, num_classes=62)\n",
    "\n",
    "# y_train = one_hot_encode(y_train)\n",
    "# y_val = one_hot_encode(y_val)\n",
    "# y_test = one_hot_encode(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aedafb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T10:18:28.167303Z",
     "iopub.status.busy": "2024-11-29T10:18:28.166975Z",
     "iopub.status.idle": "2024-11-29T10:18:28.350222Z",
     "shell.execute_reply": "2024-11-29T10:18:28.349208Z",
     "shell.execute_reply.started": "2024-11-29T10:18:28.167271Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.InputLayer(shape=[28, 28, 1]),\n",
    "    \n",
    "    # Data Augmentation\n",
    "    layers.RandomContrast(factor=0.1),\n",
    "    layers.RandomRotation(factor=0.1),\n",
    "    layers.RandomTranslation(height_factor=0.1, width_factor=0.1),\n",
    "    layers.RandomZoom(height_factor=0.1, width_factor=0.1),\n",
    "\n",
    "    # Block One\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(filters=64, kernel_size=3, activation='relu', padding='same', kernel_regularizer='l2'),\n",
    "    layers.MaxPool2D(),\n",
    "\n",
    "    # Block Two\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(filters=128, kernel_size=3, activation='relu', padding='same', kernel_regularizer='l2'),\n",
    "    layers.MaxPool2D(),\n",
    "\n",
    "    # Block Three\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(filters=256, kernel_size=3, activation='relu', padding='same'),\n",
    "    layers.Conv2D(filters=256, kernel_size=3, activation='relu', padding='same'),\n",
    "    layers.MaxPool2D(),\n",
    "\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "\n",
    "    # Head\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(128, activation='relu', kernel_regularizer='l2'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(62, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cb46ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T10:18:28.352142Z",
     "iopub.status.busy": "2024-11-29T10:18:28.351803Z",
     "iopub.status.idle": "2024-11-29T10:18:28.480023Z",
     "shell.execute_reply": "2024-11-29T10:18:28.478771Z",
     "shell.execute_reply.started": "2024-11-29T10:18:28.352111Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import shutil\n",
    "\n",
    "train_model = False\n",
    "\n",
    "saved_weights = \"/kaggle/input/char-recognition-emnist/keras/default/4/char_recog_model_emnist_v2.weights.h5\"\n",
    "if os.path.isfile(saved_weights) and not train_model:\n",
    "    model.load_weights(saved_weights)\n",
    "    history = None\n",
    "    \n",
    "else:\n",
    "    early_stopping = EarlyStopping(min_delta=0.001, patience=6, restore_best_weights=True)\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.AdamW(learning_rate=1e-3, weight_decay=1e-5)\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=50,\n",
    "        batch_size=256,\n",
    "        callbacks=[early_stopping]\n",
    "    )\n",
    "    \n",
    "    model.save_weights(\"char_recog_model_emnist.weights.h5\")\n",
    "    shutil.move(\"char_recog_model_emnist.weights.h5\", \"/kaggle/working/char_recog_model_emnist.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8eaf9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T10:18:28.482239Z",
     "iopub.status.busy": "2024-11-29T10:18:28.481792Z",
     "iopub.status.idle": "2024-11-29T10:18:28.489125Z",
     "shell.execute_reply": "2024-11-29T10:18:28.487892Z",
     "shell.execute_reply.started": "2024-11-29T10:18:28.482189Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "if history is not None:\n",
    "    history_frame = pd.DataFrame(history.history)\n",
    "    history_frame.loc[:, ['loss', 'val_loss']].plot()\n",
    "    history_frame.loc[:, ['accuracy', 'val_accuracy']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91873e14",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T10:18:28.494536Z",
     "iopub.status.busy": "2024-11-29T10:18:28.494060Z",
     "iopub.status.idle": "2024-11-29T10:18:28.506790Z",
     "shell.execute_reply": "2024-11-29T10:18:28.505042Z",
     "shell.execute_reply.started": "2024-11-29T10:18:28.494490Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dir_path = \"/kaggle/input/letters-and-digits/Images characters/\"\n",
    "dir_path_upper = \"/kaggle/input/letters-and-digits/Images characters/Uppercase\"\n",
    "dir_path_lower = \"/kaggle/input/letters-and-digits/Images characters/Lowercase\"\n",
    "\n",
    "img_path_zero = \"/kaggle/input/letters-and-digits/Images characters/zero.png\"\n",
    "img_path_drawn_zero = \"/kaggle/input/letters-and-digits/Images characters/drawn_zero.png\"\n",
    "img_path_drawn_M_close = \"/kaggle/input/letters-and-digits/Images characters/M_handwritten_close.png\"\n",
    "img_path_drawn_M_far = \"/kaggle/input/letters-and-digits/Images characters/M_handwritten_far.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe0a252",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T10:18:28.508752Z",
     "iopub.status.busy": "2024-11-29T10:18:28.508312Z",
     "iopub.status.idle": "2024-11-29T10:18:29.907083Z",
     "shell.execute_reply": "2024-11-29T10:18:29.905893Z",
     "shell.execute_reply.started": "2024-11-29T10:18:28.508706Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = dir_path_upper\n",
    "processed_images = load_and_preprocess_images_from_dir(path, inverse=True)\n",
    "# processed_image = np.array([X_test[2]])\n",
    "\n",
    "print(processed_images.shape)\n",
    "\n",
    "# Make the prediction\n",
    "predictions = model.predict(processed_images)\n",
    "\n",
    "# For multi-class classification (e.g., 62 classes):\n",
    "# Get the index of the class with the highest probability\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "print(processed_images.shape, predicted_classes.shape)\n",
    "plot_n_images(processed_images, predicted_classes, n=17, row_spacing=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0be6c05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T10:18:29.909018Z",
     "iopub.status.busy": "2024-11-29T10:18:29.908664Z",
     "iopub.status.idle": "2024-11-29T10:20:36.890709Z",
     "shell.execute_reply": "2024-11-29T10:20:36.889471Z",
     "shell.execute_reply.started": "2024-11-29T10:18:29.908985Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0319cbe3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T10:20:36.892487Z",
     "iopub.status.busy": "2024-11-29T10:20:36.892104Z",
     "iopub.status.idle": "2024-11-29T10:20:36.919469Z",
     "shell.execute_reply": "2024-11-29T10:20:36.918439Z",
     "shell.execute_reply.started": "2024-11-29T10:20:36.892443Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "# OH_predicted_classes = one_hot_encode(predicted_classes)\n",
    "accuracy = accuracy_score(y_test, predicted_classes)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28694003",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T10:21:30.634926Z",
     "iopub.status.busy": "2024-11-29T10:21:30.634536Z",
     "iopub.status.idle": "2024-11-29T10:21:31.484130Z",
     "shell.execute_reply": "2024-11-29T10:21:31.482912Z",
     "shell.execute_reply.started": "2024-11-29T10:21:30.634894Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_n_images(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844d2154",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### English Font-Number Recognition dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20ae904",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T10:21:35.708804Z",
     "iopub.status.busy": "2024-11-29T10:21:35.708377Z",
     "iopub.status.idle": "2024-11-29T10:21:35.715738Z",
     "shell.execute_reply": "2024-11-29T10:21:35.714482Z",
     "shell.execute_reply.started": "2024-11-29T10:21:35.708771Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_and_preprocess_images_from_dirs(dir_path, target_size=(28, 28), inverse=False):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i, dir in enumerate(sorted(os.listdir(dir_path))):\n",
    "        sub_dir_path = os.path.join(dir_path, dir)\n",
    "        for img in sorted(os.listdir(sub_dir_path)):\n",
    "            img_path = os.path.join(sub_dir_path, img)\n",
    "            img_array = load_and_preprocess_image(img_path, target_size=target_size, inverse=inverse)\n",
    "            img_array = np.squeeze(img_array, axis=0)\n",
    "            X.append(img_array)\n",
    "            y.append(i)\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae86dd2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T10:21:38.586587Z",
     "iopub.status.busy": "2024-11-29T10:21:38.585796Z",
     "iopub.status.idle": "2024-11-29T10:22:28.446784Z",
     "shell.execute_reply": "2024-11-29T10:22:28.445640Z",
     "shell.execute_reply.started": "2024-11-29T10:21:38.586541Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dir_path = \"/kaggle/input/english-fontnumber-recognition/Font/Font\"\n",
    "\n",
    "ds_ = image_dataset_from_directory(\n",
    "    dir_path,\n",
    "    labels='inferred',\n",
    "    label_mode = 'categorical',\n",
    "    image_size=[28, 28],\n",
    "    interpolation='nearest',\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    seed=0\n",
    ")\n",
    "\n",
    "# Data Pipeline\n",
    "def convert_to_float(image, label):\n",
    "    image = tf.image.rgb_to_grayscale(image)\n",
    "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "    return image, label\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "ds = (\n",
    "    ds_\n",
    "    .map(convert_to_float)\n",
    "    .cache()\n",
    "    .prefetch(buffer_size=AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d216dc85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T10:22:28.448887Z",
     "iopub.status.busy": "2024-11-29T10:22:28.448526Z",
     "iopub.status.idle": "2024-11-29T10:22:28.454753Z",
     "shell.execute_reply": "2024-11-29T10:22:28.453781Z",
     "shell.execute_reply.started": "2024-11-29T10:22:28.448852Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_batch(image_batch_np):\n",
    "    image_batch_preprocessed = []\n",
    "    for i in range(image_batch_np.shape[0]):\n",
    "        preprocessed_image = preprocess_image(image_batch_np[i])\n",
    "        preprocessed_image = np.expand_dims(preprocessed_image, axis=-1)\n",
    "        image_batch_preprocessed.append(preprocessed_image)\n",
    "\n",
    "    image_batch_preprocessed = np.array(image_batch_preprocessed)\n",
    "\n",
    "    return image_batch_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ce0967",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T10:22:28.456927Z",
     "iopub.status.busy": "2024-11-29T10:22:28.456233Z",
     "iopub.status.idle": "2024-11-29T10:23:50.523840Z",
     "shell.execute_reply": "2024-11-29T10:23:50.522676Z",
     "shell.execute_reply.started": "2024-11-29T10:22:28.456876Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize lists to hold the data\n",
    "X2_test = []\n",
    "y2_test = []\n",
    "\n",
    "# Iterate through the dataset and append directly to lists\n",
    "for image_batch, label_batch in ds.as_numpy_iterator():\n",
    "    X2_test.append(image_batch)\n",
    "    y2_test.append(label_batch)\n",
    "\n",
    "# Convert lists to NumPy arrays\n",
    "X2_test = np.concatenate(X2_test, axis=0)\n",
    "print(X2_test.shape)\n",
    "X2_test = np.squeeze(X2_test, axis=-1)\n",
    "X2_test = 1 - X2_test\n",
    "\n",
    "y2_test = np.concatenate(y2_test, axis=0)\n",
    "\n",
    "print(X2_test.shape, y2_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47051ee6",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-29T10:20:37.462604Z",
     "iopub.status.idle": "2024-11-29T10:20:37.462948Z",
     "shell.execute_reply": "2024-11-29T10:20:37.462792Z",
     "shell.execute_reply.started": "2024-11-29T10:20:37.462776Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dir_path = \"/kaggle/input/english-fontnumber-recognition/Font/Font\"\n",
    "\n",
    "X2_test, y2_test = load_and_preprocess_images_from_dirs(dir_path, inverse=True)\n",
    "X2_test.shape, y2_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eebdc21",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### Dataset Correct Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6287d1f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T10:37:35.184577Z",
     "iopub.status.busy": "2024-11-29T10:37:35.183576Z",
     "iopub.status.idle": "2024-11-29T10:37:35.764701Z",
     "shell.execute_reply": "2024-11-29T10:37:35.763360Z",
     "shell.execute_reply.started": "2024-11-29T10:37:35.184537Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if one-hot encoded\n",
    "if len(y2_test.shape) == 2:\n",
    "    y2_test_OH = y2_test\n",
    "    y2_test = np.argmax(y2_test_OH, axis=1)\n",
    "    \n",
    "plot_n_images(X2_test, y2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94606385",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T10:37:38.681348Z",
     "iopub.status.busy": "2024-11-29T10:37:38.680937Z",
     "iopub.status.idle": "2024-11-29T10:38:48.067122Z",
     "shell.execute_reply": "2024-11-29T10:38:48.065854Z",
     "shell.execute_reply.started": "2024-11-29T10:37:38.681309Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions2 = model.predict(X2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7d8fc2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T10:38:48.069655Z",
     "iopub.status.busy": "2024-11-29T10:38:48.069217Z",
     "iopub.status.idle": "2024-11-29T10:38:48.079638Z",
     "shell.execute_reply": "2024-11-29T10:38:48.078370Z",
     "shell.execute_reply.started": "2024-11-29T10:38:48.069607Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predicted_classes2 = np.argmax(predictions2, axis=1)\n",
    "print(predicted_classes2.shape, y2_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07578bdb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T10:38:48.081435Z",
     "iopub.status.busy": "2024-11-29T10:38:48.080960Z",
     "iopub.status.idle": "2024-11-29T10:38:48.100717Z",
     "shell.execute_reply": "2024-11-29T10:38:48.099520Z",
     "shell.execute_reply.started": "2024-11-29T10:38:48.081367Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y2_test, predicted_classes2)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202c54d2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### Dataset Predicted Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b204438",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T10:38:48.103373Z",
     "iopub.status.busy": "2024-11-29T10:38:48.102989Z",
     "iopub.status.idle": "2024-11-29T10:38:48.682888Z",
     "shell.execute_reply": "2024-11-29T10:38:48.681465Z",
     "shell.execute_reply.started": "2024-11-29T10:38:48.103335Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_n_images(X2_test[20000:], predicted_classes2[20000:])"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7160,
     "sourceId": 10705,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 1752143,
     "sourceId": 2864176,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6172398,
     "sourceId": 10044118,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 175721,
     "modelInstanceId": 153249,
     "sourceId": 181807,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 62.34682,
   "end_time": "2024-12-02T13:45:44.611109",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-02T13:44:42.264289",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
